{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Jumble Solver\n* See: https://en.wikipedia.org/wiki/Jumble \n\nThe jumble puzzle is a common newspaper puzzle, it contains a series of anagrams that must be solved. To solve, one must solve each of the individual jumbles. The circled letters are then used to create an additional anagram to be solved. In especially difficult versions, some of the anagrams in the first set can possess multiple solutions. To get the final answer, it is important to know all possible anagrams of a given series of letters.\n\nYour challenge is to solve the five Jumble puzzles using Spark, where it makes sense to do so. You may use Scala or Python (but Python is slightly preferred). If the final puzzle has multiple possible answers, you are to include an algorithm to determine the most likely one. We have provided a dictionary where the \"most common\" English words are scored (1=most frequent, 9887=least frequent, 0=not scored due to infrequency of use). For each puzzle, produce the \"most likely\" (as you determine it) final anagram produced from solving all the other anagrams.\n\nImportant Notes: Part of your task is to have this be as production ready as possible - while there are only five puzzles now, assume that there could be many more, so use Spark in the most useful way, however you don't need to spend a lot of time on tweaking the parallelization parameters. The code should be deployable and maintainable as well. Don't spend more than 24 hours to complete as much of the assignment as you can.\n\nAlso included:\nfreq_dict - keys are English Dictionary words to be used in your solving of the jumbles. Non-zero values are the frequency rankings (1=most frequent). Zero values mean that the word is too infrequent to be ranked.\npictures of the jumbles we provided for you to solve. You can put these in whatever data format you'd like for your program to read in\n\nPlease send us a link to your github repository with the following:\nYour initial data (from the jumble pictures given)\nYour code\nOutput from your code\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Utility Functions", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nimport json"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def parse_json(fileName):\n    with open(fileName) as file:\n        data = json.load(file)\n        return data"
        }, 
        {
            "source": "## Dictionary Setup", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def create_dictionary_df(freq_data):\n    schema = StructType([\n        StructField(\"word\", StringType(), False)\n        , StructField(\"freq\", IntegerType(), False)\n    ])\n    return spark.createDataFrame(freq_data.items(), schema)"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def alter_uncommon_words_indicator(dic):\n    # https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.types.IntegerType\n    MAX_INT = 2**31 - 1\n    \n    return dic.withColumn('freq', when(dic.freq == 0, MAX_INT).otherwise(dic.freq))"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def sort_letters(word):\n    return ''.join(sorted(list(word)))"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def create_sorted_word_key_column(dic):\n    sort_letters_udf = udf(sort_letters, StringType())\n    return dic.withColumn('sorted_word', sort_letters_udf(col('word')))"
        }, 
        {
            "source": "## Load External Files", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def load_dictionary(freqFileName):\n    download_from_object_storage(freqFileName)\n    freq_data = parse_json(freqFileName)\n    dic = create_dictionary_df(freq_data)\n    dic = alter_uncommon_words_indicator(dic)\n    dic = create_sorted_word_key_column(dic)\n    dic.cache()\n    return dic"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def load_game(gameFileName):\n    download_from_object_storage(gameFileName)\n    game = parse_json(gameFileName)\n    return game"
        }, 
        {
            "source": "## Gameplay Functions\nhttps://en.wikipedia.org/wiki/Jumble_algorithm", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Part 1", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def guess_word(dic, letters):\n    word = (\n        dic\n        .where(col('sorted_word') == sort_letters(letters))\n        .orderBy('freq')\n        .select('word', 'freq')\n        .first()\n        .word\n    )\n    return word"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def get_letters_by_position(word, positions): # 1-based\n    letters = []\n    for p in positions:\n        letters.append(word[p-1])\n    return letters"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def play_part1(dic, game):\n    guessedWords = []\n    part2CircledLetters = []\n    for entry in game['part1']:\n        letters = entry['letters']\n        guessedWord = guess_word(dic, letters)\n        guessedWords.append(guessedWord)\n\n        circledPositions = entry['circled']\n        circledLetters = get_letters_by_position(guessedWord, circledPositions)\n        part2CircledLetters.extend(circledLetters)\n    \n    return (guessedWords, part2CircledLetters)"
        }, 
        {
            "source": "### Part 2", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def permute_letters(letters, length):\n    from itertools import permutations\n    perms = list(permutations(letters, length))\n    return set(map(lambda w: ''.join(w), perms))"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {}
                }
            }, 
            "outputs": [], 
            "source": "def get_possible_word(dic, letters, length):\n    candidates = permute_letters(letters, length)\n    candidateWords = spark.createDataFrame(candidates, StringType())\n    candidateWords = candidateWords.withColumnRenamed('value', 'word')\n    possibleWord = (\n        dic\n        .join(candidateWords, 'word')\n        .orderBy('freq')\n        .first()\n        )\n    \n    if possibleWord is None:\n        possibleWord = \"<! Cannot Determine Word !>\"\n    else:\n        possibleWord = possibleWord.word\n    \n    return possibleWord"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def remove_used_letters(letters, word):\n    usedLetters = list(word)\n    for c in usedLetters:\n        if c in letters:\n            letters.remove(c)\n    return letters # for chaining"
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def play_part2(dic, game, circledLetters):\n    guessedWords = []\n    for numLetters in game['part2']:\n        guessedWord = get_possible_word(dic, circledLetters, numLetters)\n        guessedWords.append(guessedWord)\n        circledLetters = remove_used_letters(circledLetters, guessedWord)\n    \n    return guessedWords"
        }, 
        {
            "source": "### Combined", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def play_game(dic, gameFileName):\n    game = load_game(gameFileName)\n    part1GuessedWords, circledLetters = play_part1(dic, game)\n    part2GuessedWords = play_part2(dic, game, circledLetters)\n    return {'part1':part1GuessedWords, 'part2':part2GuessedWords}"
        }, 
        {
            "source": "## Main", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "FREQ_FILE = 'freq_dict.json'\nspark = SparkSession.builder.getOrCreate()\ndic = load_dictionary(FREQ_FILE)"
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {
                "pixiedust": {
                    "displayParams": {}
                }
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Game 1: {'part1': ['gland', 'major', 'becalm', 'lawyer'], 'part2': ['and', 'well', 'jobe']}\nGame 2: {'part1': ['blend', 'avoid', 'sychee', 'camera'], 'part2': ['are', 'dyad', 'iba']}\nGame 3: {'part1': ['stash', 'rodeo', 'indict', 'italic'], 'part2': ['each', '<! Cannot Determine Word !>']}\nGame 4: {'part1': ['dinky', 'agiel', 'encore', 'devout'], 'part2': ['addition']}\nGame 5: {'part1': ['trying', 'divert', 'seaman', 'deceit', 'shadow', 'kechel'], 'part2': ['events', '<! Cannot Determine Word !>']}\n"
                }
            ], 
            "source": "print(\"Game 1: \" + str(play_game(dic, 'game1.json')))\nprint(\"Game 2: \" + str(play_game(dic, 'game2.json')))\nprint(\"Game 3: \" + str(play_game(dic, 'game3.json')))\nprint(\"Game 4: \" + str(play_game(dic, 'game4.json')))\nprint(\"Game 5: \" + str(play_game(dic, 'game5.json')))"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}